{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation for finetuning the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>congress</th>\n",
       "      <th>chamber</th>\n",
       "      <th>committee</th>\n",
       "      <th>committee_short</th>\n",
       "      <th>year</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>hearing_id</th>\n",
       "      <th>type</th>\n",
       "      <th>last_name</th>\n",
       "      <th>...</th>\n",
       "      <th>L4claims</th>\n",
       "      <th>L4claims_multi_hot</th>\n",
       "      <th>L1policyclaims</th>\n",
       "      <th>L2policyclaims</th>\n",
       "      <th>L3policyclaims</th>\n",
       "      <th>L4policyclaims</th>\n",
       "      <th>L2policyclaims_multi_hot</th>\n",
       "      <th>labelled</th>\n",
       "      <th>L2dummy_4_45</th>\n",
       "      <th>L2dummy_4_3456</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "      <td>SENATE</td>\n",
       "      <td>Committee on Environment and Public Works</td>\n",
       "      <td>Environment and Public Works</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003-04-08</td>\n",
       "      <td>The Clear Skies Act of 2003</td>\n",
       "      <td>108shrg91748</td>\n",
       "      <td>witness</td>\n",
       "      <td>Rogers</td>\n",
       "      <td>...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 178 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   congress chamber                                  committee  \\\n",
       "0       108  SENATE  Committee on Environment and Public Works   \n",
       "\n",
       "                committee_short  year       date                        title  \\\n",
       "0  Environment and Public Works  2003 2003-04-08  The Clear Skies Act of 2003   \n",
       "\n",
       "     hearing_id     type last_name  ... L4claims  \\\n",
       "0  108shrg91748  witness    Rogers  ...      [0]   \n",
       "\n",
       "                  L4claims_multi_hot L1policyclaims L2policyclaims  \\\n",
       "0  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]            0.0          [0.0]   \n",
       "\n",
       "  L3policyclaims L4policyclaims  L2policyclaims_multi_hot labelled  \\\n",
       "0          [0.0]          [0.0]  [1, 0, 0, 0, 0, 0, 0, 0]     True   \n",
       "\n",
       "  L2dummy_4_45  L2dummy_4_3456  \n",
       "0          0.0             0.0  \n",
       "\n",
       "[1 rows x 178 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import openai\n",
    "import os\n",
    "import tiktoken\n",
    "\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_json('../Data/cat_hearings_03_10_utterances_witnesses_MoCs_labels.json')\n",
    "# Save the unlabelled data\n",
    "df_unlabelled = df[df.labelled == False].reset_index(drop=True).copy()\n",
    "# Subset labelled data \n",
    "df = df[df.labelled == True].reset_index(drop=True)\n",
    "# Add a new dummy combining policy claim 4.4 and 4.5\n",
    "df[\"L2dummy_4_45\"] = df.apply(lambda x: [1.0 if i > 0 else 0.0 for i in [x.L2dummy_4_4 + x.L2dummy_4_5]][0], axis = 1)\n",
    "# Add a new dummy combining policy claim 4.3 ,4.4, 4.5 and 4.6\n",
    "df[\"L2dummy_4_3456\"] = df.apply(lambda x: [1.0 if i > 0 else 0.0 for i in [x.L2dummy_4_3 + x.L2dummy_4_4 + x.L2dummy_4_5 + x.L2dummy_4_6]][0], axis = 1)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data set size:  1181\n",
      "Validation data set size:  253\n",
      "Testing data set size:  253\n",
      "Training data level 2 policy claims:\n",
      "\n",
      "Claim 4_1 count:  276 (23.37%)\n",
      "Claim 4_2 count:  127 (10.75%)\n",
      "Claim 4_3456 count: 169 (14.31%)\n",
      "\n",
      "Validation data level 2 policy claims:\n",
      "Claim 4_1 count:  60 (23.72%)\n",
      "Claim 4_2 count:  27 (10.67%)\n",
      "Claim 4_3456 count: 36 (14.23%)\n",
      "\n",
      "Testing data level 2 policy claims:\n",
      "Claim 4_1 count:  38 (15.02%)\n",
      "Claim 4_2 count:  17 (6.72%)\n",
      "Claim 4_3456 count: 35 (13.83%)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training, validation and testing data (70-15-15 split)\n",
    "\n",
    "CLAIMS = ['L2dummy_4_1', 'L2dummy_4_2', 'L2dummy_4_3456']\n",
    "\n",
    "# Create stratified random train, val and test data sets\n",
    "\n",
    "df[\"CLAIMS\"] = df.loc[:,CLAIMS].values.tolist()\n",
    "\n",
    "# Reserve a testing data set of only the randomly sampled labelled data (First batch)\n",
    "train, test = train_test_split(df[df.batch == \"Batch 1: Random sample\"],\n",
    "                               test_size=0.364,\n",
    "                               random_state=12, \n",
    "                               stratify = df[df.batch == \"Batch 1: Random sample\"].CLAIMS, \n",
    "                               shuffle=True)\n",
    "\n",
    "# Merge the active learning batches with the remaining random sample training data\n",
    "train = pd.concat([train, df[df.batch != \"Batch 1: Random sample\"]])\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "train, val = train_test_split(train, \n",
    "                              test_size=0.176, \n",
    "                              random_state=12,\n",
    "                              stratify = train.CLAIMS, \n",
    "                              shuffle=True)\n",
    "\n",
    "# Print the number or paragraphs in each data set\n",
    "print(\"Training data set size: \", len(train))\n",
    "print(\"Validation data set size: \", len(val))\n",
    "print(\"Testing data set size: \", len(test))\n",
    "\n",
    "# Transform the labels into the correct form (drop 4.7 as no observations in data)\n",
    "train[\"labels\"] = train.loc[:,CLAIMS].values.astype(int).tolist()\n",
    "val[\"labels\"] = val.loc[:,CLAIMS].values.astype(int).tolist()\n",
    "test[\"labels\"] = test.loc[:,CLAIMS].values.astype(int).tolist()\n",
    "\n",
    "\n",
    "# Print the number of level 2 policy claims in each data set and the percentage of the total\n",
    "print(\"Training data level 2 policy claims:\\n\")\n",
    "for i in range(1, 3):\n",
    "    print(\"Claim 4_{} count: \".format(i), train[\"L2dummy_4_{}\".format(i)].value_counts()[1], \"({}%)\".format(round(train[\"L2dummy_4_{}\".format(i)].value_counts()[1] / len(train) * 100, 2)))\n",
    "print(\"Claim 4_3456 count:\", train[\"L2dummy_4_3456\"].value_counts()[1], \"({}%)\".format(round(train[\"L2dummy_4_3456\"].value_counts()[1] / len(train) * 100, 2)))\n",
    "print()\n",
    "print(\"Validation data level 2 policy claims:\")\n",
    "for i in range(1, 3):\n",
    "    print(\"Claim 4_{} count: \".format(i), val[\"L2dummy_4_{}\".format(i)].value_counts()[1], \"({}%)\".format(round(val[\"L2dummy_4_{}\".format(i)].value_counts()[1] / len(val) * 100, 2)))\n",
    "print(\"Claim 4_3456 count:\", val[\"L2dummy_4_3456\"].value_counts()[1], \"({}%)\".format(round(val[\"L2dummy_4_3456\"].value_counts()[1] / len(val) * 100, 2)))\n",
    "print()\n",
    "print(\"Testing data level 2 policy claims:\")\n",
    "for i in range(1, 3):\n",
    "    print(\"Claim 4_{} count: \".format(i), test[\"L2dummy_4_{}\".format(i)].value_counts()[1], \"({}%)\".format(round(test[\"L2dummy_4_{}\".format(i)].value_counts()[1] / len(test) * 100, 2)))\n",
    "print(\"Claim 4_3456 count:\", test[\"L2dummy_4_3456\"].value_counts()[1], \"({}%)\".format(round(test[\"L2dummy_4_3456\"].value_counts()[1] / len(test) * 100, 2)))\n",
    "\n",
    "\n",
    "# Note, there are no occurences of the new claim 4_7: No need for more action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING:\n",
      "Training word count:  83293\n",
      "\n",
      "INFERENCE:\n",
      "FFI word count:  154668\n",
      "Carbon-intensive Industry word count:  163005\n",
      "Business & Services word count:  130533\n"
     ]
    }
   ],
   "source": [
    "# Word-counts\n",
    "print(\"TRAINING:\")\n",
    "print(\"Training word count: \", train.word_count.sum())\n",
    "\n",
    "print(\"\")\n",
    "print(\"INFERENCE:\")\n",
    "print(\"FFI word count: \", df_unlabelled[df_unlabelled.witness_category == \"Fossil Fuel Industry\"].word_count.sum())\n",
    "print(\"Carbon-intensive Industry word count: \", df_unlabelled[df_unlabelled.witness_category == \"Carbon-intensive Industry\"].word_count.sum())\n",
    "print(\"Business & Services word count: \", df_unlabelled[df_unlabelled.witness_category == \"Business & Services\"].word_count.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING:\n",
      "Training token count:  99286\n",
      "\n",
      "INFERENCE:\n",
      "Unlabelled contrarian token count: 94535\n",
      "FFI token count: 160353\n",
      "Carbon-intensive Industry token count: 182896\n",
      "Business & Services token count: 141100\n",
      "MoC token count: 1902562\n"
     ]
    }
   ],
   "source": [
    "# Token counts\n",
    "print(\"TRAINING:\")\n",
    "print(\"Training token count: \", \n",
    "      train.text.apply(lambda x: len(enc.encode(x))).sum() +\n",
    "      train.shape[0])\n",
    "\n",
    "print(\"\")\n",
    "print(\"INFERENCE:\")\n",
    "print(\"Unlabelled contrarian token count:\",\n",
    "       df_unlabelled[df_unlabelled.witness_contrarian == \"Contrarian\"].text.apply(lambda x: len(enc.encode(x))).sum() + \n",
    "       df_unlabelled[df_unlabelled.witness_contrarian == \"Contrarian\"].shape[0])\n",
    "print(\"FFI token count:\",\n",
    "       df_unlabelled[(df_unlabelled.witness_category == \"Fossil Fuel Industry\") & (df_unlabelled.witness_contrarian != \"Contrarian\")].text.apply(lambda x: len(enc.encode(x))).sum() + \n",
    "       df_unlabelled[(df_unlabelled.witness_category == \"Fossil Fuel Industry\") & (df_unlabelled.witness_contrarian != \"Contrarian\")].shape[0])\n",
    "print(\"Carbon-intensive Industry token count:\", \n",
    "      df_unlabelled[(df_unlabelled.witness_category == \"Carbon-intensive Industry\") & (df_unlabelled.witness_contrarian != \"Contrarian\")].text.apply(lambda x: len(enc.encode(x))).sum() +\n",
    "      df_unlabelled[(df_unlabelled.witness_category == \"Carbon-intensive Industry\") & (df_unlabelled.witness_contrarian != \"Contrarian\")].shape[0])\n",
    "print(\"Business & Services token count:\", \n",
    "      df_unlabelled[(df_unlabelled.witness_category == \"Business & Services\") & (df_unlabelled.witness_contrarian != \"Contrarian\")].text.apply(lambda x: len(enc.encode(x))).sum() +\n",
    "      df_unlabelled[(df_unlabelled.witness_category == \"Business & Services\") & (df_unlabelled.witness_contrarian != \"Contrarian\")].shape[0])\n",
    "print(\"MoC token count:\", \n",
    "      df_unlabelled[df_unlabelled.type == \"MoC\"].text.apply(lambda x: len(enc.encode(x))).sum() +\n",
    "      df_unlabelled[df_unlabelled.type == \"MoC\"].shape[0])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b138a8faad971cc852f62bcf00f59ea0e31721743ea2c5a866ca26adf572e75"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
