{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation\n",
    "\n",
    "We will assess model performance of the different classifiers and see if ensemble models will improve model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import openai\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set openai API key\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mn/Library/CloudStorage/OneDrive-UniversityofExeter/Projects/GitHub/contrarian-discourses-against-cap-and-trade/Code'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance on the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>predicted_labels_roberta</th>\n",
       "      <th>predicted_labels_chat</th>\n",
       "      <th>predicted_labels_llm</th>\n",
       "      <th>predicted_labels_ada</th>\n",
       "      <th>predicted_labels_curie</th>\n",
       "      <th>predicted_labels_davinci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>[1, 0, 1]</td>\n",
       "      <td>[1, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>[1, 1, 0]</td>\n",
       "      <td>[1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[1, 1, 0]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels predicted_labels_roberta predicted_labels_chat  \\\n",
       "0   [0, 0, 1]                [0, 0, 1]             [0, 0, 1]   \n",
       "1   [0, 0, 0]                [0, 0, 0]             [0, 0, 0]   \n",
       "2   [0, 0, 0]                [0, 0, 0]             [0, 0, 0]   \n",
       "3   [0, 0, 0]                [0, 0, 1]             [0, 0, 0]   \n",
       "4   [0, 1, 0]                [0, 1, 0]             [1, 0, 0]   \n",
       "5   [0, 0, 0]                [0, 0, 0]             [0, 0, 0]   \n",
       "6   [1, 0, 0]                [0, 0, 0]             [1, 0, 0]   \n",
       "7   [0, 0, 1]                [0, 0, 1]             [0, 0, 0]   \n",
       "8   [0, 0, 0]                [0, 0, 0]             [0, 0, 0]   \n",
       "9   [0, 1, 0]                [0, 0, 0]             [0, 1, 0]   \n",
       "10  [0, 0, 0]                [0, 0, 0]             [0, 0, 0]   \n",
       "11  [0, 0, 0]                [0, 0, 0]             [0, 0, 0]   \n",
       "12  [0, 0, 0]                [0, 0, 1]             [0, 0, 1]   \n",
       "13  [0, 0, 0]                [0, 0, 0]             [0, 0, 0]   \n",
       "14  [0, 0, 0]                [0, 0, 0]             [1, 0, 0]   \n",
       "15  [0, 0, 0]                [0, 0, 0]             [0, 0, 0]   \n",
       "16  [0, 0, 0]                [0, 0, 0]             [1, 0, 0]   \n",
       "17  [1, 0, 0]                [1, 0, 0]             [1, 0, 0]   \n",
       "18  [0, 0, 0]                [0, 0, 0]             [0, 0, 0]   \n",
       "19  [1, 0, 0]                [1, 0, 0]             [1, 0, 0]   \n",
       "20  [1, 1, 0]                [0, 1, 0]             [0, 1, 0]   \n",
       "21  [0, 0, 0]                [0, 0, 0]             [0, 0, 0]   \n",
       "22  [0, 0, 0]                [0, 0, 0]             [0, 0, 0]   \n",
       "23  [0, 1, 0]                [0, 1, 0]             [0, 1, 0]   \n",
       "24  [0, 0, 0]                [0, 0, 0]             [0, 0, 0]   \n",
       "\n",
       "   predicted_labels_llm predicted_labels_ada predicted_labels_curie  \\\n",
       "0             [0, 0, 1]            [0, 0, 0]              [0, 0, 1]   \n",
       "1             [0, 0, 0]            [0, 0, 0]              [0, 0, 0]   \n",
       "2             [0, 0, 0]            [0, 0, 0]              [0, 0, 0]   \n",
       "3             [0, 0, 0]            [0, 0, 0]              [0, 0, 1]   \n",
       "4             [0, 1, 0]            [0, 0, 0]              [0, 1, 0]   \n",
       "5             [0, 0, 0]            [0, 0, 0]              [0, 0, 0]   \n",
       "6             [0, 1, 0]            [1, 0, 0]              [1, 0, 0]   \n",
       "7             [0, 0, 0]            [0, 0, 0]              [0, 0, 0]   \n",
       "8             [0, 0, 0]            [0, 0, 0]              [0, 0, 0]   \n",
       "9             [0, 0, 0]            [0, 0, 0]              [0, 0, 0]   \n",
       "10            [0, 0, 0]            [0, 0, 0]              [0, 0, 0]   \n",
       "11            [0, 0, 0]            [0, 0, 0]              [0, 0, 0]   \n",
       "12            [0, 0, 0]            [0, 0, 0]              [0, 0, 1]   \n",
       "13            [0, 0, 0]            [0, 0, 0]              [0, 0, 0]   \n",
       "14            [0, 1, 0]            [0, 0, 0]              [0, 0, 0]   \n",
       "15            [0, 0, 0]            [0, 0, 0]              [0, 0, 0]   \n",
       "16            [0, 0, 0]            [1, 0, 0]              [1, 0, 1]   \n",
       "17            [1, 0, 0]            [1, 0, 0]              [1, 0, 0]   \n",
       "18            [0, 1, 0]            [0, 0, 0]              [0, 0, 0]   \n",
       "19            [0, 0, 0]            [1, 0, 0]              [1, 1, 0]   \n",
       "20            [0, 0, 0]            [0, 0, 0]              [0, 1, 0]   \n",
       "21            [0, 0, 0]            [0, 0, 0]              [0, 0, 0]   \n",
       "22            [0, 0, 0]            [0, 0, 0]              [0, 0, 0]   \n",
       "23            [0, 1, 0]            [0, 1, 0]              [0, 1, 0]   \n",
       "24            [0, 0, 0]            [0, 0, 0]              [0, 0, 0]   \n",
       "\n",
       "   predicted_labels_davinci  \n",
       "0                 [0, 0, 1]  \n",
       "1                 [0, 0, 0]  \n",
       "2                 [0, 0, 0]  \n",
       "3                 [0, 0, 1]  \n",
       "4                 [0, 1, 0]  \n",
       "5                 [0, 0, 0]  \n",
       "6                 [1, 0, 0]  \n",
       "7                 [0, 0, 0]  \n",
       "8                 [0, 0, 0]  \n",
       "9                 [0, 0, 0]  \n",
       "10                [0, 0, 0]  \n",
       "11                [0, 0, 0]  \n",
       "12                [0, 0, 1]  \n",
       "13                [0, 0, 0]  \n",
       "14                [1, 0, 0]  \n",
       "15                [0, 0, 0]  \n",
       "16                [1, 0, 1]  \n",
       "17                [1, 0, 0]  \n",
       "18                [0, 0, 0]  \n",
       "19                [1, 1, 0]  \n",
       "20                [0, 1, 0]  \n",
       "21                [0, 0, 0]  \n",
       "22                [0, 0, 0]  \n",
       "23                [0, 1, 0]  \n",
       "24                [0, 0, 0]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = pd.read_json('../Classifiers/Data/cat_hearings_03_10_val.json')\n",
    "\n",
    "# # Append the predicted_labels_adas to the validation set\n",
    "val = val.merge(pd.read_json('../Classifiers/Data/cat_hearings_03_10_val_roberta_labels.json').loc[:,(\"id\", \"predicted_labels_roberta\")])\n",
    "val = val.merge(pd.read_json('../Classifiers/Data/cat_hearings_03_10_val_zeroshot_labels.json').loc[:,(\"id\", \"predicted_labels_chat\")])\n",
    "val = val.merge(pd.read_json('../Classifiers/Data/cat_hearings_03_10_val_zeroshot_labels.json').loc[:,(\"id\", \"predicted_labels_llm\")])\n",
    "val = val.merge(pd.read_json('../Classifiers/Data/cat_hearings_03_10_val_ada_labels.json').loc[:,(\"id\", \"predicted_labels_ada\")])\n",
    "val = val.merge(pd.read_json('../Classifiers/Data/cat_hearings_03_10_val_curie_labels.json').loc[:,(\"id\", \"predicted_labels_curie\")])\n",
    "val = val.merge(pd.read_json('../Classifiers/Data/cat_hearings_03_10_val_davinci_labels.json').loc[:,(\"id\", \"predicted_labels_davinci\")])\n",
    "\n",
    "val.iloc[0:25,179:186]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the no claim 4 label to the predicted labels whereever none of the three sublcaims are predicted\n",
    "\n",
    "val.labels = val.labels.apply(lambda x: [0 if sum(x) > 0 else 1] +  x)\n",
    "val.predicted_labels_roberta = val.predicted_labels_roberta.apply(lambda x: [0 if sum(x) > 0 else 1] +  x)\n",
    "val.predicted_labels_chat = val.predicted_labels_chat.apply(lambda x: [0 if sum(x) > 0 else 1] +  x)\n",
    "val.predicted_labels_llm = val.predicted_labels_llm.apply(lambda x: [0 if sum(x) > 0 else 1] +  x)\n",
    "val.predicted_labels_ada = val.predicted_labels_ada.apply(lambda x: [0 if sum(x) > 0 else 1] +  x)\n",
    "val.predicted_labels_curie = val.predicted_labels_curie.apply(lambda x: [0 if sum(x) > 0 else 1] +  x)\n",
    "val.predicted_labels_davinci = val.predicted_labels_davinci.apply(lambda x: [0 if sum(x) > 0 else 1] +  x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance at the sub-claim level\n",
      "\n",
      "RoBERta\n",
      "-----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87       153\n",
      "           1       0.83      0.75      0.79        60\n",
      "           2       0.75      0.67      0.71        27\n",
      "           3       0.58      0.72      0.64        36\n",
      "\n",
      "   micro avg       0.82      0.79      0.80       276\n",
      "   macro avg       0.76      0.75      0.75       276\n",
      "weighted avg       0.83      0.79      0.81       276\n",
      " samples avg       0.82      0.81      0.81       276\n",
      "\n",
      "Chat\n",
      "-----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       153\n",
      "           1       0.68      0.78      0.73        60\n",
      "           2       0.57      0.30      0.39        27\n",
      "           3       0.56      0.25      0.35        36\n",
      "\n",
      "   micro avg       0.76      0.70      0.73       276\n",
      "   macro avg       0.66      0.54      0.58       276\n",
      "weighted avg       0.74      0.70      0.71       276\n",
      " samples avg       0.76      0.73      0.74       276\n",
      "\n",
      "LLM\n",
      "-----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.95      0.83       153\n",
      "           1       0.87      0.45      0.59        60\n",
      "           2       0.38      0.22      0.28        27\n",
      "           3       0.64      0.19      0.30        36\n",
      "\n",
      "   micro avg       0.73      0.67      0.70       276\n",
      "   macro avg       0.66      0.45      0.50       276\n",
      "weighted avg       0.72      0.67      0.66       276\n",
      " samples avg       0.73      0.70      0.71       276\n",
      "\n",
      "ADA\n",
      "-----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84       153\n",
      "           1       0.73      0.72      0.72        60\n",
      "           2       0.80      0.59      0.68        27\n",
      "           3       0.67      0.06      0.10        36\n",
      "\n",
      "   micro avg       0.76      0.73      0.75       276\n",
      "   macro avg       0.74      0.57      0.59       276\n",
      "weighted avg       0.75      0.73      0.70       276\n",
      " samples avg       0.76      0.75      0.75       276\n",
      "\n",
      "Curie\n",
      "-----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85       153\n",
      "           1       0.74      0.77      0.75        60\n",
      "           2       0.75      0.67      0.71        27\n",
      "           3       0.53      0.44      0.48        36\n",
      "\n",
      "   micro avg       0.78      0.77      0.77       276\n",
      "   macro avg       0.72      0.69      0.70       276\n",
      "weighted avg       0.77      0.77      0.77       276\n",
      " samples avg       0.79      0.78      0.78       276\n",
      "\n",
      "Davinci\n",
      "-----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       153\n",
      "           1       0.78      0.83      0.81        60\n",
      "           2       0.78      0.78      0.78        27\n",
      "           3       0.61      0.53      0.57        36\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       276\n",
      "   macro avg       0.76      0.76      0.76       276\n",
      "weighted avg       0.81      0.82      0.82       276\n",
      " samples avg       0.83      0.83      0.83       276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification reports\n",
    "print(\"Performance at the sub-claim level\\n\")\n",
    "\n",
    "print(\"RoBERta\\n-----------\")\n",
    "print(classification_report(val.labels.values.tolist(), \n",
    "                            val.predicted_labels_roberta.values.tolist()))\n",
    "\n",
    "print(\"Chat\\n-----------\")\n",
    "print(classification_report(val.labels.values.tolist(),\n",
    "                            val.predicted_labels_chat.values.tolist()))\n",
    "\n",
    "print(\"LLM\\n-----------\")\n",
    "print(classification_report(val.labels.values.tolist(),\n",
    "                            val.predicted_labels_llm.values.tolist()))\n",
    "\n",
    "print(\"ADA\\n-----------\")\n",
    "print(classification_report(val.labels.values.tolist(),\n",
    "                            val.predicted_labels_ada.values.tolist()))\n",
    "\n",
    "print(\"Curie\\n-----------\")\n",
    "print(classification_report(val.labels.values.tolist(),\n",
    "                            val.predicted_labels_curie.values.tolist()))\n",
    "\n",
    "\n",
    "print(\"Davinci\\n-----------\")\n",
    "print(classification_report(val.labels.values.tolist(),\n",
    "                            val.predicted_labels_davinci.values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance at the claim level\n",
      "\n",
      "RoBERta\n",
      "-----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87       153\n",
      "           1       0.78      0.85      0.81       100\n",
      "\n",
      "    accuracy                           0.85       253\n",
      "   macro avg       0.84      0.85      0.84       253\n",
      "weighted avg       0.85      0.85      0.85       253\n",
      "\n",
      "Chat\n",
      "-----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       153\n",
      "           1       0.76      0.75      0.75       100\n",
      "\n",
      "    accuracy                           0.81       253\n",
      "   macro avg       0.80      0.80      0.80       253\n",
      "weighted avg       0.81      0.81      0.81       253\n",
      "\n",
      "LLM\n",
      "-----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.95      0.83       153\n",
      "           1       0.86      0.50      0.63       100\n",
      "\n",
      "    accuracy                           0.77       253\n",
      "   macro avg       0.80      0.72      0.73       253\n",
      "weighted avg       0.79      0.77      0.75       253\n",
      "\n",
      "ADA\n",
      "-----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84       153\n",
      "           1       0.83      0.58      0.68       100\n",
      "\n",
      "    accuracy                           0.79       253\n",
      "   macro avg       0.80      0.75      0.76       253\n",
      "weighted avg       0.79      0.79      0.78       253\n",
      "\n",
      "Curie\n",
      "-----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85       153\n",
      "           1       0.78      0.75      0.77       100\n",
      "\n",
      "    accuracy                           0.82       253\n",
      "   macro avg       0.81      0.81      0.81       253\n",
      "weighted avg       0.82      0.82      0.82       253\n",
      "\n",
      "Davinci\n",
      "-----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       153\n",
      "           1       0.84      0.81      0.82       100\n",
      "\n",
      "    accuracy                           0.86       253\n",
      "   macro avg       0.86      0.85      0.85       253\n",
      "weighted avg       0.86      0.86      0.86       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification reports\n",
    "print(\"Performance at the claim level\\n\")\n",
    "\n",
    "print(\"RoBERta\\n-----------\")\n",
    "print(classification_report([1 if sum(i)>0 else 0 for i in val.labels.apply(lambda x: x[1:4])], \n",
    "                            [1 if sum(i)>0 else 0 for i in val.predicted_labels_roberta.apply(lambda x: x[1:4])]))\n",
    "\n",
    "print(\"Chat\\n-----------\")\n",
    "print(classification_report([1 if sum(i)>0 else 0 for i in val.labels.apply(lambda x: x[1:4])],\n",
    "                            [1 if sum(i)>0 else 0 for i in val.predicted_labels_chat.apply(lambda x: x[1:4])]))\n",
    "\n",
    "print(\"LLM\\n-----------\")\n",
    "print(classification_report([1 if sum(i)>0 else 0 for i in val.labels.apply(lambda x: x[1:4])],\n",
    "                            [1 if sum(i)>0 else 0 for i in val.predicted_labels_llm.apply(lambda x: x[1:4])]))\n",
    "\n",
    "print(\"ADA\\n-----------\")\n",
    "print(classification_report([1 if sum(i)>0 else 0 for i in val.labels.apply(lambda x: x[1:4])],\n",
    "                            [1 if sum(i)>0 else 0 for i in val.predicted_labels_ada.apply(lambda x: x[1:4])]))\n",
    "\n",
    "print(\"Curie\\n-----------\")\n",
    "print(classification_report([1 if sum(i)>0 else 0 for i in val.labels.apply(lambda x: x[1:4])],\n",
    "                            [1 if sum(i)>0 else 0 for i in val.predicted_labels_curie.apply(lambda x: x[1:4])]))\n",
    "\n",
    "print(\"Davinci\\n-----------\")\n",
    "print(classification_report([1 if sum(i)>0 else 0 for i in val.labels.apply(lambda x: x[1:4])],\n",
    "                            [1 if sum(i)>0 else 0 for i in val.predicted_labels_davinci.apply(lambda x: x[1:4])]))\n",
    "                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble model\n",
      "-----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.82      0.87       153\n",
      "           1       0.75      0.87      0.81        60\n",
      "           2       0.70      0.78      0.74        27\n",
      "           3       0.55      0.75      0.64        36\n",
      "\n",
      "   micro avg       0.80      0.82      0.81       276\n",
      "   macro avg       0.74      0.80      0.76       276\n",
      "weighted avg       0.83      0.82      0.81       276\n",
      " samples avg       0.82      0.82      0.81       276\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.82      0.87       153\n",
      "           1       0.77      0.92      0.84       100\n",
      "\n",
      "    accuracy                           0.86       253\n",
      "   macro avg       0.85      0.87      0.86       253\n",
      "weighted avg       0.87      0.86      0.86       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate ensemble predictions where a labels is predicted if it is predicted by at least 2 models\n",
    "\n",
    "minimum_agreement = 1\n",
    "\n",
    "val['predicted_labels_ensemble'] = pd.DataFrame(zip(\n",
    "    val.apply(lambda x: 1 if (\n",
    "          x['predicted_labels_roberta'][0]\n",
    "        #   + x['predicted_labels_curie'][0]\n",
    "          + x['predicted_labels_davinci'][0]\n",
    "          >= minimum_agreement) else 0, axis=1),\n",
    "    val.apply(lambda x: 1 if (\n",
    "          x['predicted_labels_roberta'][1]\n",
    "        #   + x['predicted_labels_curie'][1]\n",
    "          + x['predicted_labels_davinci'][1]\n",
    "          >= minimum_agreement) else 0, axis=1),\n",
    "    val.apply(lambda x: 1 if (\n",
    "          x['predicted_labels_roberta'][2]\n",
    "        #   + x['predicted_labels_curie'][2]\n",
    "          + x['predicted_labels_davinci'][2]\n",
    "          >= minimum_agreement) else 0, axis=1),\n",
    "    val.apply(lambda x: 1 if (\n",
    "          x['predicted_labels_roberta'][3]\n",
    "        #   + x['predicted_labels_curie'][3]\n",
    "          + x['predicted_labels_davinci'][3]\n",
    "          >= minimum_agreement) else 0, axis=1),\n",
    "    )).values.tolist()\n",
    "\n",
    "# Make logical correction to the \"no-claim\" category (If no sub-claim is predicted, then the claim is predicted as \"no-claim\")\n",
    "val.predicted_labels_ensemble = val.predicted_labels_ensemble.apply(lambda x: [0 if sum(x[1:4])> 0 else 1] + x[1:4])\n",
    "\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Ensemble model\\n-----------\")\n",
    "print(classification_report(val['labels'].values.tolist(), val['predicted_labels_ensemble'].values.tolist()))\n",
    "print(classification_report([1 if sum(i)>0 else 0 for i in val['labels'].apply(lambda x: x[1:4])], \n",
    "                            [1 if sum(i)>0 else 0 for i in val['predicted_labels_ensemble'].apply(lambda x: x[1:4])]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble model\n",
      "-----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.88       153\n",
      "           1       0.88      0.72      0.79        60\n",
      "           2       0.86      0.67      0.75        27\n",
      "           3       0.67      0.50      0.57        36\n",
      "\n",
      "   micro avg       0.83      0.80      0.82       276\n",
      "   macro avg       0.81      0.70      0.75       276\n",
      "weighted avg       0.83      0.80      0.81       276\n",
      " samples avg       0.83      0.82      0.82       276\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.88       153\n",
      "           1       0.87      0.74      0.80       100\n",
      "\n",
      "    accuracy                           0.85       253\n",
      "   macro avg       0.86      0.83      0.84       253\n",
      "weighted avg       0.86      0.85      0.85       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate ensemble predictions where a labels is predicted if it is predicted by at least 2 models\n",
    "\n",
    "minimum_agreement = 2\n",
    "\n",
    "val['predicted_labels_ensemble'] = pd.DataFrame(zip(\n",
    "    val.apply(lambda x: 1 if (\n",
    "          x['predicted_labels_roberta'][0]\n",
    "        #   + x['predicted_labels_curie'][0]\n",
    "          + x['predicted_labels_davinci'][0]\n",
    "          >= minimum_agreement) else 0, axis=1),\n",
    "    val.apply(lambda x: 1 if (\n",
    "          x['predicted_labels_roberta'][1]\n",
    "        #   + x['predicted_labels_curie'][1]\n",
    "          + x['predicted_labels_davinci'][1]\n",
    "          >= minimum_agreement) else 0, axis=1),\n",
    "    val.apply(lambda x: 1 if (\n",
    "          x['predicted_labels_roberta'][2]\n",
    "        #   + x['predicted_labels_curie'][2]\n",
    "          + x['predicted_labels_davinci'][2]\n",
    "          >= minimum_agreement) else 0, axis=1),\n",
    "    val.apply(lambda x: 1 if (\n",
    "          x['predicted_labels_roberta'][3]\n",
    "        #   + x['predicted_labels_curie'][3]\n",
    "          + x['predicted_labels_davinci'][3]\n",
    "          >= minimum_agreement) else 0, axis=1),\n",
    "    )).values.tolist()\n",
    "\n",
    "# Make logical correction to the \"no-claim\" category (If no sub-claim is predicted, then the claim is predicted as \"no-claim\")\n",
    "val.predicted_labels_ensemble = val.predicted_labels_ensemble.apply(lambda x: [0 if sum(x[1:4])> 0 else 1] + x[1:4])\n",
    "\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Ensemble model\\n-----------\")\n",
    "print(classification_report(val['labels'].values.tolist(), val['predicted_labels_ensemble'].values.tolist()))\n",
    "print(classification_report([1 if sum(i)>0 else 0 for i in val['labels'].apply(lambda x: x[1:4])], \n",
    "                            [1 if sum(i)>0 else 0 for i in val['predicted_labels_ensemble'].apply(lambda x: x[1:4])]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of the final model on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>predicted_labels_roberta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels predicted_labels_roberta\n",
       "0   [0, 0, 0]                [0, 1, 0]\n",
       "1   [0, 0, 1]                [0, 0, 1]\n",
       "2   [0, 0, 0]                [0, 0, 0]\n",
       "3   [0, 0, 0]                [0, 0, 0]\n",
       "4   [0, 0, 0]                [0, 0, 0]\n",
       "5   [0, 0, 0]                [0, 0, 0]\n",
       "6   [0, 0, 0]                [0, 0, 0]\n",
       "7   [0, 0, 0]                [0, 0, 0]\n",
       "8   [0, 0, 0]                [0, 0, 0]\n",
       "9   [0, 0, 0]                [0, 0, 0]\n",
       "10  [0, 0, 0]                [0, 0, 0]\n",
       "11  [0, 0, 1]                [0, 0, 1]\n",
       "12  [0, 0, 0]                [0, 0, 0]\n",
       "13  [0, 0, 0]                [0, 0, 0]\n",
       "14  [0, 0, 0]                [0, 0, 0]\n",
       "15  [0, 0, 0]                [0, 0, 1]\n",
       "16  [1, 0, 0]                [1, 0, 0]\n",
       "17  [0, 0, 0]                [0, 0, 0]\n",
       "18  [0, 0, 0]                [1, 0, 0]\n",
       "19  [0, 0, 0]                [1, 0, 0]\n",
       "20  [0, 0, 0]                [0, 0, 0]\n",
       "21  [0, 0, 1]                [0, 0, 1]\n",
       "22  [0, 0, 0]                [0, 0, 0]\n",
       "23  [0, 0, 0]                [0, 0, 0]\n",
       "24  [0, 0, 0]                [0, 0, 0]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_json('../Classifiers/Data/cat_hearings_03_10_test.json')\n",
    "\n",
    "# # Append the predicted_labels_adas to the validation set\n",
    "test = test.merge(pd.read_json('../Classifiers/Data/cat_hearings_03_10_test_roberta_labels.json').loc[:,(\"id\", \"predicted_labels_roberta\")])\n",
    "\n",
    "test.iloc[0:25,179:186]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the no claim 4 label to the predicted labels whereever none of the three sublcaims are predicted\n",
    "\n",
    "test.labels = test.labels.apply(lambda x: [0 if sum(x) > 0 else 1] +  x)\n",
    "test.predicted_labels_roberta = test.predicted_labels_roberta.apply(lambda x: [0 if sum(x) > 0 else 1] +  x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance at the sub-claim level\n",
      "\n",
      "RoBERta\n",
      "-----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.81      0.88       178\n",
      "           1       0.67      0.84      0.74        38\n",
      "           2       0.44      0.41      0.42        17\n",
      "           3       0.53      0.74      0.62        35\n",
      "\n",
      "   micro avg       0.79      0.78      0.79       268\n",
      "   macro avg       0.65      0.70      0.67       268\n",
      "weighted avg       0.83      0.78      0.80       268\n",
      " samples avg       0.81      0.80      0.80       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification reports\n",
    "print(\"Performance at the sub-claim level\\n\")\n",
    "\n",
    "print(\"RoBERta\\n-----------\")\n",
    "print(classification_report(test.labels.values.tolist(), \n",
    "                            test.predicted_labels_roberta.values.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance at the claim level\n",
      "\n",
      "RoBERta\n",
      "-----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.81      0.88       178\n",
      "           1       0.67      0.91      0.77        75\n",
      "\n",
      "    accuracy                           0.84       253\n",
      "   macro avg       0.81      0.86      0.83       253\n",
      "weighted avg       0.87      0.84      0.85       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification reports\n",
    "print(\"Performance at the claim level\\n\")\n",
    "\n",
    "print(\"RoBERta\\n-----------\")\n",
    "print(classification_report([1 if sum(i)>0 else 0 for i in test.labels.apply(lambda x: x[1:4])], \n",
    "                            [1 if sum(i)>0 else 0 for i in test.predicted_labels_roberta.apply(lambda x: x[1:4])]))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b138a8faad971cc852f62bcf00f59ea0e31721743ea2c5a866ca26adf572e75"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
