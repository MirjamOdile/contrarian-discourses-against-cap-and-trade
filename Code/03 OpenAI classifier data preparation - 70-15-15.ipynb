{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation for finetuning the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>congress</th>\n",
       "      <th>chamber</th>\n",
       "      <th>committee</th>\n",
       "      <th>committee_short</th>\n",
       "      <th>year</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>hearing_id</th>\n",
       "      <th>type</th>\n",
       "      <th>last_name</th>\n",
       "      <th>...</th>\n",
       "      <th>L4claims</th>\n",
       "      <th>L4claims_multi_hot</th>\n",
       "      <th>L1policyclaims</th>\n",
       "      <th>L2policyclaims</th>\n",
       "      <th>L3policyclaims</th>\n",
       "      <th>L4policyclaims</th>\n",
       "      <th>L2policyclaims_multi_hot</th>\n",
       "      <th>labelled</th>\n",
       "      <th>L2dummy_4_45</th>\n",
       "      <th>L2dummy_4_3456</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "      <td>SENATE</td>\n",
       "      <td>Committee on Environment and Public Works</td>\n",
       "      <td>Environment and Public Works</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003-04-08</td>\n",
       "      <td>The Clear Skies Act of 2003</td>\n",
       "      <td>108shrg91748</td>\n",
       "      <td>witness</td>\n",
       "      <td>Rogers</td>\n",
       "      <td>...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 178 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   congress chamber                                  committee  \\\n",
       "0       108  SENATE  Committee on Environment and Public Works   \n",
       "\n",
       "                committee_short  year       date                        title  \\\n",
       "0  Environment and Public Works  2003 2003-04-08  The Clear Skies Act of 2003   \n",
       "\n",
       "     hearing_id     type last_name  ... L4claims  \\\n",
       "0  108shrg91748  witness    Rogers  ...      [0]   \n",
       "\n",
       "                  L4claims_multi_hot L1policyclaims L2policyclaims  \\\n",
       "0  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]            0.0          [0.0]   \n",
       "\n",
       "  L3policyclaims L4policyclaims  L2policyclaims_multi_hot labelled  \\\n",
       "0          [0.0]          [0.0]  [1, 0, 0, 0, 0, 0, 0, 0]     True   \n",
       "\n",
       "  L2dummy_4_45  L2dummy_4_3456  \n",
       "0          0.0             0.0  \n",
       "\n",
       "[1 rows x 178 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import openai\n",
    "import os\n",
    "\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_json('../Data/cat_hearings_03_10_utterances_witnesses_MoCs_labels.json')\n",
    "df = df[df.labelled == True].reset_index(drop=True)\n",
    "# Add a new dummy combining policy claim 4.4 and 4.5\n",
    "df[\"L2dummy_4_45\"] = df.apply(lambda x: [1.0 if i > 0 else 0.0 for i in [x.L2dummy_4_4 + x.L2dummy_4_5]][0], axis = 1)\n",
    "# Add a new dummy combining policy claim 4.3 ,4.4, 4.5 and 4.6\n",
    "df[\"L2dummy_4_3456\"] = df.apply(lambda x: [1.0 if i > 0 else 0.0 for i in [x.L2dummy_4_3 + x.L2dummy_4_4 + x.L2dummy_4_5 + x.L2dummy_4_6]][0], axis = 1)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mn/Library/CloudStorage/OneDrive-UniversityofExeter/Projects/GitHub/contrarian-discourses-against-cap-and-trade/Code'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch 1: Random sample                                        694\n",
       "Batch 3: Active learning sample (claim 4)                     517\n",
       "Batch 2: Active learning sample (oversampling rare claims)    476\n",
       "Name: batch, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.batch.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data set size:  1181\n",
      "Validation data set size:  253\n",
      "Testing data set size:  253\n",
      "Training data level 2 policy claims:\n",
      "\n",
      "Claim 4_1 count:  276 (23.37%)\n",
      "Claim 4_2 count:  128 (10.84%)\n",
      "Claim 4_3456 count: 169 (14.31%)\n",
      "\n",
      "Validation data level 2 policy claims:\n",
      "Claim 4_1 count:  60 (23.72%)\n",
      "Claim 4_2 count:  27 (10.67%)\n",
      "Claim 4_3456 count: 36 (14.23%)\n",
      "\n",
      "Testing data level 2 policy claims:\n",
      "Claim 4_1 count:  38 (15.02%)\n",
      "Claim 4_2 count:  17 (6.72%)\n",
      "Claim 4_3456 count: 35 (13.83%)\n"
     ]
    }
   ],
   "source": [
    "CLAIMS = ['L2dummy_4_1', 'L2dummy_4_2', 'L2dummy_4_3456']\n",
    "\n",
    "# Split the data into training, validation and testing data (70-15-15 split)\n",
    "\n",
    "# Create stratified random train, val and test data sets\n",
    "\n",
    "df[\"CLAIMS\"] = df.loc[:,CLAIMS].values.tolist()\n",
    "\n",
    "# Reserve a testing data set of only the randomly sampled labelled data (First batch)\n",
    "train, test = train_test_split(df[df.batch == \"Batch 1: Random sample\"],\n",
    "                               test_size=0.364,\n",
    "                               random_state=12, \n",
    "                               stratify = df[df.batch == \"Batch 1: Random sample\"].CLAIMS, \n",
    "                               shuffle=True)\n",
    "\n",
    "# Merge the active learning batches with the remaining random sample training data\n",
    "train = pd.concat([train, df[df.batch != \"Batch 1: Random sample\"]])\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "train, val = train_test_split(train, \n",
    "                              test_size=0.176, \n",
    "                              random_state=12,\n",
    "                              stratify = train.CLAIMS, \n",
    "                              shuffle=True)\n",
    "\n",
    "# Print the number or paragraphs in each data set\n",
    "print(\"Training data set size: \", len(train))\n",
    "print(\"Validation data set size: \", len(val))\n",
    "print(\"Testing data set size: \", len(test))\n",
    "\n",
    "# Transform the labels into the correct form (drop 4.7 as no observations in data)\n",
    "train[\"labels\"] = train.loc[:,CLAIMS].values.astype(int).tolist()\n",
    "val[\"labels\"] = val.loc[:,CLAIMS].values.astype(int).tolist()\n",
    "test[\"labels\"] = test.loc[:,CLAIMS].values.astype(int).tolist()\n",
    "\n",
    "# Print the number of level 2 policy claims in each data set and the percentage of the total\n",
    "print(\"Training data level 2 policy claims:\\n\")\n",
    "for i in range(1, 3):\n",
    "    print(\"Claim 4_{} count: \".format(i), train[\"L2dummy_4_{}\".format(i)].value_counts()[1], \"({}%)\".format(round(train[\"L2dummy_4_{}\".format(i)].value_counts()[1] / len(train) * 100, 2)))\n",
    "print(\"Claim 4_3456 count:\", train[\"L2dummy_4_3456\"].value_counts()[1], \"({}%)\".format(round(train[\"L2dummy_4_3456\"].value_counts()[1] / len(train) * 100, 2)))\n",
    "print()\n",
    "print(\"Validation data level 2 policy claims:\")\n",
    "for i in range(1, 3):\n",
    "    print(\"Claim 4_{} count: \".format(i), val[\"L2dummy_4_{}\".format(i)].value_counts()[1], \"({}%)\".format(round(val[\"L2dummy_4_{}\".format(i)].value_counts()[1] / len(val) * 100, 2)))\n",
    "print(\"Claim 4_3456 count:\", val[\"L2dummy_4_3456\"].value_counts()[1], \"({}%)\".format(round(val[\"L2dummy_4_3456\"].value_counts()[1] / len(val) * 100, 2)))\n",
    "print()\n",
    "print(\"Testing data level 2 policy claims:\")\n",
    "for i in range(1, 3):\n",
    "    print(\"Claim 4_{} count: \".format(i), test[\"L2dummy_4_{}\".format(i)].value_counts()[1], \"({}%)\".format(round(test[\"L2dummy_4_{}\".format(i)].value_counts()[1] / len(test) * 100, 2)))\n",
    "print(\"Claim 4_3456 count:\", test[\"L2dummy_4_3456\"].value_counts()[1], \"({}%)\".format(round(test[\"L2dummy_4_3456\"].value_counts()[1] / len(test) * 100, 2)))\n",
    "\n",
    "\n",
    "# Note, there are no occurences of the new claim 4_7: No need for more action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the train / valid / test datasets\n",
    "train.to_json(\"../Classifiers/Data/cat_hearings_03_10_train.json\")\n",
    "val.to_json(\"../Classifiers/Data/cat_hearings_03_10_val.json\")\n",
    "test.to_json(\"../Classifiers/Data/cat_hearings_03_10_test.json\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 1: All claims\n",
    "We transform the dataset into a pandas dataframe, with a column for prompt and completion. The prompt contains the email from the mailing list, and the completion is a name of the sport, either hockey or baseball. For demonstration purposes only and speed of fine-tuning we take only 300 examples. In a real use case the more examples the better the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all level 2 policy dummies for the train, val and test data to jsonl files\n",
    "pd.DataFrame(zip(train.text, train.L1dummy_1), columns = ['prompt','completion']).to_json(\"../Classifiers/Data/train_1.jsonl\", orient='records', lines=True)\n",
    "pd.DataFrame(zip(train.text, train.L1dummy_2), columns = ['prompt','completion']).to_json(\"../Classifiers/Data/train_2.jsonl\", orient='records', lines=True)\n",
    "pd.DataFrame(zip(train.text, train.L1dummy_3), columns = ['prompt','completion']).to_json(\"../Classifiers/Data/train_3.jsonl\", orient='records', lines=True)\n",
    "pd.DataFrame(zip(train.text, train.L1dummy_4), columns = ['prompt','completion']).to_json(\"../Classifiers/Data/train_4.jsonl\", orient='records', lines=True)\n",
    "pd.DataFrame(zip(train.text, train.L1dummy_5), columns = ['prompt','completion']).to_json(\"../Classifiers/Data/train_5.jsonl\", orient='records', lines=True)\n",
    "\n",
    "pd.DataFrame(zip(val.text, val.L1dummy_1), columns = ['prompt','completion']).to_json(\"../Classifiers/Data/val_1.jsonl\", orient='records', lines=True)\n",
    "pd.DataFrame(zip(val.text, val.L1dummy_2), columns = ['prompt','completion']).to_json(\"../Classifiers/Data/val_2.jsonl\", orient='records', lines=True)\n",
    "pd.DataFrame(zip(val.text, val.L1dummy_3), columns = ['prompt','completion']).to_json(\"../Classifiers/Data/val_3.jsonl\", orient='records', lines=True)\n",
    "pd.DataFrame(zip(val.text, val.L1dummy_4), columns = ['prompt','completion']).to_json(\"../Classifiers/Data/val_4.jsonl\", orient='records', lines=True)\n",
    "pd.DataFrame(zip(val.text, val.L1dummy_5), columns = ['prompt','completion']).to_json(\"../Classifiers/Data/val_5.jsonl\", orient='records', lines=True)\n",
    "\n",
    "pd.DataFrame(zip(test.text, test.L1dummy_1), columns = ['prompt','completion']).to_json(\"../Classifiers/Data/test_1.jsonl\", orient='records', lines=True)\n",
    "pd.DataFrame(zip(test.text, test.L1dummy_2), columns = ['prompt','completion']).to_json(\"../Classifiers/Data/test_2.jsonl\", orient='records', lines=True)\n",
    "pd.DataFrame(zip(test.text, test.L1dummy_3), columns = ['prompt','completion']).to_json(\"../Classifiers/Data/test_3.jsonl\", orient='records', lines=True)\n",
    "pd.DataFrame(zip(test.text, test.L1dummy_4), columns = ['prompt','completion']).to_json(\"../Classifiers/Data/test_4.jsonl\", orient='records', lines=True)\n",
    "pd.DataFrame(zip(test.text, test.L1dummy_5), columns = ['prompt','completion']).to_json(\"../Classifiers/Data/test_5.jsonl\", orient='records', lines=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation tool\n",
    "We can now use a data preparation tool which will suggest a few improvements to our dataset before fine-tuning. Before launching the tool we update the openai library to ensure we're using the latest data preparation tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 1181 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: - [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: - [Recommended] Would you like to split into training and validation set? [Y/n]: \n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: \n",
      "Wrote modified file to `../Classifiers/Data/train_1_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../Classifiers/Data/train_1_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".0\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 30.68 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 1181 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: - [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: - [Recommended] Would you like to split into training and validation set? [Y/n]: \n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: \n",
      "Wrote modified file to `../Classifiers/Data/train_2_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../Classifiers/Data/train_2_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".0\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 30.68 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 1181 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: - [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: - [Recommended] Would you like to split into training and validation set? [Y/n]: \n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: \n",
      "Wrote modified file to `../Classifiers/Data/train_3_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../Classifiers/Data/train_3_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".0\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 30.68 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 1181 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: - [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: - [Recommended] Would you like to split into training and validation set? [Y/n]: \n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: \n",
      "Wrote modified file to `../Classifiers/Data/train_4_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../Classifiers/Data/train_4_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".0\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 30.68 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 1181 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: - [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: - [Recommended] Would you like to split into training and validation set? [Y/n]: \n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: \n",
      "Wrote modified file to `../Classifiers/Data/train_5_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../Classifiers/Data/train_5_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".0\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 30.68 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 253 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: - [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: - [Recommended] Would you like to split into training and validation set? [Y/n]: \n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: \n",
      "Wrote modified file to `../Classifiers/Data/val_1_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../Classifiers/Data/val_1_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".0\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 8.41 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 253 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: - [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: - [Recommended] Would you like to split into training and validation set? [Y/n]: \n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: \n",
      "Wrote modified file to `../Classifiers/Data/val_2_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../Classifiers/Data/val_2_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".0\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 8.41 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 253 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: - [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: - [Recommended] Would you like to split into training and validation set? [Y/n]: \n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: \n",
      "Wrote modified file to `../Classifiers/Data/val_3_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../Classifiers/Data/val_3_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".0\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 8.41 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 253 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: - [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: - [Recommended] Would you like to split into training and validation set? [Y/n]: \n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: \n",
      "Wrote modified file to `../Classifiers/Data/val_4_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../Classifiers/Data/val_4_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".0\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 8.41 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 253 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: - [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: - [Recommended] Would you like to split into training and validation set? [Y/n]: \n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: \n",
      "Wrote modified file to `../Classifiers/Data/val_5_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../Classifiers/Data/val_5_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".0\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 8.41 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 253 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: - [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: - [Recommended] Would you like to split into training and validation set? [Y/n]: \n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: \n",
      "Wrote modified file to `../Classifiers/Data/test_1_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../Classifiers/Data/test_1_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".0\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 8.41 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 253 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: - [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: - [Recommended] Would you like to split into training and validation set? [Y/n]: \n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: \n",
      "Wrote modified file to `../Classifiers/Data/test_2_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../Classifiers/Data/test_2_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".0\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 8.41 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 253 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: - [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: - [Recommended] Would you like to split into training and validation set? [Y/n]: \n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: \n",
      "Wrote modified file to `../Classifiers/Data/test_3_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../Classifiers/Data/test_3_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".0\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 8.41 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 253 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: - [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: - [Recommended] Would you like to split into training and validation set? [Y/n]: \n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: \n",
      "Wrote modified file to `../Classifiers/Data/test_4_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../Classifiers/Data/test_4_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".0\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 8.41 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 253 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: - [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: - [Recommended] Would you like to split into training and validation set? [Y/n]: \n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: \n",
      "Wrote modified file to `../Classifiers/Data/test_5_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../Classifiers/Data/test_5_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".0\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 8.41 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "# Use the openai tools to prepare the data for fine-tuning\n",
    "!echo -e \"Y\\nY\\nn\\nY\"|openai tools fine_tunes.prepare_data -f ../Classifiers/Data/train_1.jsonl\n",
    "!echo -e \"Y\\nY\\nn\\nY\"|openai tools fine_tunes.prepare_data -f ../Classifiers/Data/train_2.jsonl\n",
    "!echo -e \"Y\\nY\\nn\\nY\"|openai tools fine_tunes.prepare_data -f ../Classifiers/Data/train_3.jsonl\n",
    "!echo -e \"Y\\nY\\nn\\nY\"|openai tools fine_tunes.prepare_data -f ../Classifiers/Data/train_4.jsonl\n",
    "!echo -e \"Y\\nY\\nn\\nY\"|openai tools fine_tunes.prepare_data -f ../Classifiers/Data/train_5.jsonl\n",
    "\n",
    "!echo -e \"Y\\nY\\nn\\nY\"|openai tools fine_tunes.prepare_data -f ../Classifiers/Data/val_1.jsonl\n",
    "!echo -e \"Y\\nY\\nn\\nY\"|openai tools fine_tunes.prepare_data -f ../Classifiers/Data/val_2.jsonl\n",
    "!echo -e \"Y\\nY\\nn\\nY\"|openai tools fine_tunes.prepare_data -f ../Classifiers/Data/val_3.jsonl\n",
    "!echo -e \"Y\\nY\\nn\\nY\"|openai tools fine_tunes.prepare_data -f ../Classifiers/Data/val_4.jsonl\n",
    "!echo -e \"Y\\nY\\nn\\nY\"|openai tools fine_tunes.prepare_data -f ../Classifiers/Data/val_5.jsonl\n",
    "\n",
    "!echo -e \"Y\\nY\\nn\\nY\"|openai tools fine_tunes.prepare_data -f ../Classifiers/Data/test_1.jsonl\n",
    "!echo -e \"Y\\nY\\nn\\nY\"|openai tools fine_tunes.prepare_data -f ../Classifiers/Data/test_2.jsonl\n",
    "!echo -e \"Y\\nY\\nn\\nY\"|openai tools fine_tunes.prepare_data -f ../Classifiers/Data/test_3.jsonl\n",
    "!echo -e \"Y\\nY\\nn\\nY\"|openai tools fine_tunes.prepare_data -f ../Classifiers/Data/test_4.jsonl\n",
    "!echo -e \"Y\\nY\\nn\\nY\"|openai tools fine_tunes.prepare_data -f ../Classifiers/Data/test_5.jsonl\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 2: Policy claims (IV)\n",
    "We transform the dataset into a pandas dataframe, with a column for prompt and completion. The prompt contains the email from the mailing list, and the completion is a name of the sport, either hockey or baseball. For demonstration purposes only and speed of fine-tuning we take only 300 examples. In a real use case the more examples the better the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all level 2 policy dummies for the train, val and test data to jsonl files\n",
    "pd.DataFrame(zip(train.text, train.L2dummy_4_1), columns = ['prompt','completion']).to_json(\"../Classifiers/Data/train_4_1.jsonl\", orient='records', lines=True)\n",
    "pd.DataFrame(zip(train.text, train.L2dummy_4_2), columns = ['prompt','completion']).to_json(\"../Classifiers/Data/train_4_2.jsonl\", orient='records', lines=True)\n",
    "pd.DataFrame(zip(train.text, train.L2dummy_4_3456), columns = ['prompt','completion']).to_json(\"../Classifiers/Data/train_4_3456.jsonl\", orient='records', lines=True)\n",
    "\n",
    "\n",
    "pd.DataFrame(zip(val.text, val.L2dummy_4_1), columns = ['prompt','completion']).to_json(\"../Classifiers/Data/val_4_1.jsonl\", orient='records', lines=True)\n",
    "pd.DataFrame(zip(val.text, val.L2dummy_4_2), columns = ['prompt','completion']).to_json(\"../Classifiers/Data/val_4_2.jsonl\", orient='records', lines=True)\n",
    "pd.DataFrame(zip(val.text, val.L2dummy_4_3456), columns = ['prompt','completion']).to_json(\"../Classifiers/Data/val_4_3456.jsonl\", orient='records', lines=True)\n",
    "\n",
    "pd.DataFrame(zip(test.text, test.L2dummy_4_1), columns = ['prompt','completion']).to_json(\"../Classifiers/Data/test_4_1.jsonl\", orient='records', lines=True)\n",
    "pd.DataFrame(zip(test.text, test.L2dummy_4_2), columns = ['prompt','completion']).to_json(\"../Classifiers/Data/test_4_2.jsonl\", orient='records', lines=True)\n",
    "pd.DataFrame(zip(test.text, test.L2dummy_4_3456), columns = ['prompt','completion']).to_json(\"../Classifiers/Data/test_4_3456.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation tool\n",
    "We can now use a data preparation tool which will suggest a few improvements to our dataset before fine-tuning. Before launching the tool we update the openai library to ensure we're using the latest data preparation tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 1181 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: - [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: - [Recommended] Would you like to split into training and validation set? [Y/n]: \n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: \n",
      "Wrote modified file to `../Classifiers/Data/train_4_1_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../Classifiers/Data/train_4_1_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".0\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 30.68 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 1181 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: - [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: - [Recommended] Would you like to split into training and validation set? [Y/n]: \n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: \n",
      "Wrote modified file to `../Classifiers/Data/train_4_2_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../Classifiers/Data/train_4_2_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".0\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 30.68 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 1181 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: - [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: - [Recommended] Would you like to split into training and validation set? [Y/n]: \n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: \n",
      "Wrote modified file to `../Classifiers/Data/train_4_3456_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../Classifiers/Data/train_4_3456_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".0\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 30.68 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 253 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: - [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: - [Recommended] Would you like to split into training and validation set? [Y/n]: \n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: \n",
      "Wrote modified file to `../Classifiers/Data/val_4_1_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../Classifiers/Data/val_4_1_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".0\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 8.41 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 253 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: - [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: - [Recommended] Would you like to split into training and validation set? [Y/n]: \n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: \n",
      "Wrote modified file to `../Classifiers/Data/val_4_2_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../Classifiers/Data/val_4_2_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".0\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 8.41 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 253 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: - [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: - [Recommended] Would you like to split into training and validation set? [Y/n]: \n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: \n",
      "Wrote modified file to `../Classifiers/Data/val_4_3456_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../Classifiers/Data/val_4_3456_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".0\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 8.41 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 253 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: - [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: - [Recommended] Would you like to split into training and validation set? [Y/n]: \n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: \n",
      "Wrote modified file to `../Classifiers/Data/test_4_1_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../Classifiers/Data/test_4_1_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".0\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 8.41 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 253 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: - [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: - [Recommended] Would you like to split into training and validation set? [Y/n]: \n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: \n",
      "Wrote modified file to `../Classifiers/Data/test_4_2_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../Classifiers/Data/test_4_2_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".0\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 8.41 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 253 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: - [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: - [Recommended] Would you like to split into training and validation set? [Y/n]: \n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: \n",
      "Wrote modified file to `../Classifiers/Data/test_4_3456_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../Classifiers/Data/test_4_3456_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".0\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 8.41 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "# Use the openai tools to prepare the data for fine-tuning\n",
    "!echo -e \"Y\\nY\\nn\\nY\"|openai tools fine_tunes.prepare_data -f ../Classifiers/Data/train_4_1.jsonl\n",
    "!echo -e \"Y\\nY\\nn\\nY\"|openai tools fine_tunes.prepare_data -f ../Classifiers/Data/train_4_2.jsonl\n",
    "!echo -e \"Y\\nY\\nn\\nY\"|openai tools fine_tunes.prepare_data -f ../Classifiers/Data/train_4_3456.jsonl\n",
    "\n",
    "!echo -e \"Y\\nY\\nn\\nY\"|openai tools fine_tunes.prepare_data -f ../Classifiers/Data/val_4_1.jsonl\n",
    "!echo -e \"Y\\nY\\nn\\nY\"|openai tools fine_tunes.prepare_data -f ../Classifiers/Data/val_4_2.jsonl\n",
    "!echo -e \"Y\\nY\\nn\\nY\"|openai tools fine_tunes.prepare_data -f ../Classifiers/Data/val_4_3456.jsonl\n",
    "\n",
    "!echo -e \"Y\\nY\\nn\\nY\"|openai tools fine_tunes.prepare_data -f ../Classifiers/Data/test_4_1.jsonl\n",
    "!echo -e \"Y\\nY\\nn\\nY\"|openai tools fine_tunes.prepare_data -f ../Classifiers/Data/test_4_2.jsonl\n",
    "!echo -e \"Y\\nY\\nn\\nY\"|openai tools fine_tunes.prepare_data -f ../Classifiers/Data/test_4_3456.jsonl\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b138a8faad971cc852f62bcf00f59ea0e31721743ea2c5a866ca26adf572e75"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
